{
 "cells": [
  {
   "cell_type": "raw",
   "id": "3a50cd40-c244-43b0-b1d6-7ee400c62227",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Using OpenAI Deep Research: Absorbing multiple sources of information and merging into output\"\n",
    "description: \"Trying to see if Deep Research can create a good starting point for further research into a niche topic.\"\n",
    "author: \"Amelie Zhang\"\n",
    "date: \"4/7/2024\"\n",
    "categories:\n",
    "  - LLMs\n",
    "  - marketing\n",
    "  - chart making\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b47fc4b-2496-43f5-a8ba-e35c62e4d270",
   "metadata": {},
   "source": [
    "# Original, lengthy prompt:\n",
    "I'm doing a project for my macroeconomics class about the Argentine Great Depression (1998-2001) and I need you to help me in research, application to the class, and structuring/creating the content for my presentation. \n",
    "\n",
    "To start, I want you to just give a few paragraphs summary on what happened in this Argentine Great Depression, and what the results were. Give it to me in simple, concise, yet accurate sentences for me to best understand the event quickly.\n",
    "\n",
    "After that, I want you to utilize the deep research to meet the presentation requirements:\n",
    "\"Background: 1-2 slides which provide an overview of the country’s economy and\n",
    "relevant historical background.\n",
    "• The overview of the economy can include a description of the large sectors\n",
    "(in terms of value added) in the economy, a comparison of GDP per capita\n",
    "to neighboring countries at the time, the demographics of the country (if\n",
    "relevant), etc.\n",
    "2) Overview of the crisis: 1-2 slides that describes the events leading to the crisis, how\n",
    "the crisis unfolded, and the ensuing recovery.\n",
    "3) Analysis: 2-4 slides in which you analyze the economic crisis using the tools learned\n",
    "in class (primarily the IS-LM model). You need to decide how the shock should be\n",
    "modeled in the framework, and interpret the unfolding of the crisis and its recovery\n",
    "using the model. In doing so, you should present data on the behavior of key\n",
    "economic variables, such as real GDP, unemployment, investment, consumption,\n",
    "exports, imports, and the exchange rate.\"\n",
    "For each of these three components, I want in depth explanations and fitting content so that I can make a presentation with your response. I also want to emphasize the imporance of the third component. I need to very simply yet accurately apply the IS-LM model to the event. Let me know if you have any questions about what class materials you should be refrencing for this section.\n",
    "For economic data, utilize World bank: https://data.worldbank.org/\n",
    "2. International monetary fund: https://data.imf.org/\n",
    "3. OECD: https://data.oecd.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9415c080-ccb9-45d4-81b3-6737cc1e43be",
   "metadata": {},
   "source": [
    "# GPT's follow up questions:\n",
    "Got it! To create the best possible presentation and analysis, could you please clarify a couple of things:\n",
    "\n",
    "Do you already have a specific country or countries in mind for GDP per capita comparisons in the background section, or should I choose neighboring ones like Brazil, Chile, and Uruguay?\n",
    "\n",
    "Do you have any class notes or slides on the IS-LM model that describe what assumptions or simplifications your professor prefers (e.g., fixed vs. flexible exchange rates, openness to trade, capital mobility)? That way I can make sure to tailor the IS-LM analysis to your course.\n",
    "\n",
    "Would you prefer charts and tables included in the response that you can directly insert into your slides, or mostly written explanations that you can then convert into slides?\n",
    "\n",
    "Once I have these details, I’ll dive into the full research and presentation structure for you!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac778fc-0f24-4045-98c1-37fa4e12f9f3",
   "metadata": {},
   "source": [
    "# GPT response:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1cf814-771c-4047-b065-75fed9fb3d9b",
   "metadata": {},
   "source": [
    "<img src=\"a.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f85a7b-eb1f-4cf8-af3b-ec8a7a82e7b8",
   "metadata": {},
   "source": [
    "# Asking GPT about the deep research abilities:\n",
    "GPT’s deep research abilities stem from three core strengths:\n",
    "\n",
    "1. **Massive Knowledge Base**:\n",
    "   GPT has access to a vast corpus of books, academic papers, technical manuals, and web content up to its training cut-off. This enables it to provide informed summaries, synthesize conflicting viewpoints, and outline complex theories across diverse disciplines.\n",
    "\n",
    "2. **Pattern Recognition and Synthesis**:\n",
    "   It excels at connecting disparate concepts, identifying trends, and producing structured outputs from fragmented information. For instance, it can analyze historical patterns in economic crises or trace philosophical ideas across different schools of thought.\n",
    "\n",
    "3. **Iterative Query Handling**:\n",
    "   GPT refines research outputs based on follow-up questions, allowing users to probe deeper or adjust the focus. This makes it particularly effective for exploratory research and hypothesis development.\n",
    "\n",
    "However, it’s important to remember that GPT cannot directly access new data after its training or independently verify real-time facts without external tools. When used carefully alongside human critical thinking and fact-checking, it’s a highly efficient research assistant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb03f1f5-1d25-40a2-8f50-e249020576db",
   "metadata": {},
   "source": [
    "# Asking GPT to envision itself as a human researcher:\n",
    "If GPT’s research abilities were personified as a human, it would likely resemble a seasoned academic polymath—someone who:\n",
    "\n",
    "Dresses in a clean, timeless style—think tailored blazers, well-worn leather notebooks, and always carrying a slim tablet or a stack of annotated papers.\n",
    "\n",
    "Personality-wise, is endlessly curious, unfazed by complex debates, and able to switch between topics like philosophy, particle physics, and modern art without missing a beat.\n",
    "\n",
    "Social Demeanor is calm and measured, preferring to listen carefully before offering deeply considered, well-reasoned insights.\n",
    "\n",
    "Workspace would be a minimalist but highly organized study, filled with books from every genre, a large screen for data visualization, and a whiteboard filled with interconnected ideas.\n",
    "\n",
    "Basically, it’s the professor everyone goes to when they’re stuck—but who will always remind you to double-check the latest data just in case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3645359f-b208-4806-93f7-628f3ba63d10",
   "metadata": {},
   "source": [
    "# Reference Photo that it generated:\n",
    "<img src=\"b.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628df4c4-1cce-4c9f-9c56-424a92056d06",
   "metadata": {},
   "source": [
    "# Reflection:\n",
    "Thinking about the above interactions, the LLM is inching closer and closer towards human-ness, which I think is both fascinating and scary at the same time. Though I am interested in seeing what LLMs can do, at the same time I am not sure if its wide scale usability is always a good thing. It could be easily swayed by the information that it grasps on to first, which might make the outcomes leanening towards some type of bias.\n",
    "\n",
    "The second half of this post asking GPT to reflect on itself as a human researcher was also interesting, as it broke down the human into different aspects like clothing, personality, and social demeanor. The photo it generated was also strangely realistic. Overall, this was an interesting experiment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
