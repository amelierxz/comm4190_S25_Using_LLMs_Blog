[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Explorations with LLMs",
    "section": "",
    "text": "My expertise: Hong Kong\n\n\n\n\n\n\nLLMs\n\n\nin class\n\n\n\nBest city\n\n\n\n\n\nFeb 12, 2024\n\n\nAn LLM User\n\n\n\n\n\n\n\n\n\n\n\n\nGame theory problem\n\n\n\n\n\n\nLLMs\n\n\ngame theory\n\n\nlogic\n\n\n\nRolling dice\n\n\n\n\n\nFeb 7, 2024\n\n\nAn LLM User\n\n\n\n\n\n\n\n\n\n\n\n\nA test post\n\n\n\n\n\n\nLLMs\n\n\nprompting\n\n\nlogic\n\n\n\nAn example post from a Jupyter notebook\n\n\n\n\n\nFeb 2, 2024\n\n\nAn LLM User\n\n\n\n\n\n\n\n\n\n\n\n\nInteresting word logic problem\n\n\n\n\n\n\nLLMs\n\n\nword problem\n\n\nlogic\n\n\n\nTrying to figure out how to use this thing\n\n\n\n\n\nFeb 2, 2024\n\n\nAn LLM User\n\n\n\n\n\n\n\n\n\n\n\n\nThird post about a math problem\n\n\n\n\n\n\nLLMs\n\n\nprompting\n\n\nlogic\n\n\n\nTrying to figure out how to use this thing\n\n\n\n\n\nFeb 2, 2024\n\n\nAn LLM User\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/logic problem/index.html",
    "href": "posts/logic problem/index.html",
    "title": "Interesting word logic problem",
    "section": "",
    "text": "A logic problem for LLMs\n\nRead the following and see if you can answer the question:\n\n\nThe Stolen Key (created by GPT 4o)\n\nFour friends‚ÄîAlex, Ben, Cara, and Dana‚Äîwere the only people in a locked house when the front door key went missing. Each of them made a statement:\n\nAlex: ‚ÄúI didn‚Äôt take the key.‚Äù\n\nBen: ‚ÄúCara took the key.‚Äù\n\nCara: ‚ÄúDana is lying.‚Äù\n\nDana: ‚ÄúBen is lying.‚Äù\n\nOnly one of them is telling the truth. Who stole the key?\n\n\nHow do LLMs response to the prompt?\n\nGPT4o\nLet‚Äôs analyze the statements logically:\n\nOnly one person is telling the truth.\nIf Ben were telling the truth (‚ÄúCara took the key‚Äù), then all other statements must be false.\n\nAlex saying ‚ÄúI didn‚Äôt take the key‚Äù would be false ‚Üí meaning Alex did take the key. This contradicts Ben‚Äôs claim.\nTherefore, Ben is lying.\n\n\nSince Ben is lying, Cara did not take the key. That means we must find another truth-teller.\n\nIf Cara were telling the truth (‚ÄúDana is lying‚Äù), then:\n\nDana saying ‚ÄúBen is lying‚Äù would be false, meaning Ben is telling the truth.\nBut we already established that Ben was lying, so this contradicts our assumption.\n\n\nSince Cara cannot be the truth-teller either, let‚Äôs check Dana.\n\nIf Dana were telling the truth (‚ÄúBen is lying‚Äù), then:\n\nBen‚Äôs statement (‚ÄúCara took the key‚Äù) is false ‚Üí meaning Cara did NOT take the key.\nThat makes Alex‚Äôs statement (‚ÄúI didn‚Äôt take the key‚Äù) false ‚Üí meaning Alex DID take the key.\n\n\nSince this setup is consistent and only one truth-teller exists, the key was stolen by Alex.\n\n\nGPT4o1\nAnswer: Alex took the key.\nHere‚Äôs a quick way to see why:\n\nAssume Dana is telling the truth (‚ÄúBen is lying‚Äù).\nIf Ben is lying, then ‚ÄúCara took the key‚Äù is false, so Cara did not take the key.\nBecause only one statement can be true, Alex‚Äôs and Cara‚Äôs statements must be false:\n\nAlex‚Äôs statement ‚ÄúI didn‚Äôt take the key‚Äù is false, so Alex did take the key.\nCara‚Äôs statement ‚ÄúDana is lying‚Äù is false, meaning Dana is indeed telling the truth.\n\n\nAll conditions are satisfied with Dana telling the truth and Alex as the thief.\n\n\nAnalysis of LLM Reasoning\nThis problem is an example of how LLMs process logical constraints. Given the one-truth constraint, LLMs systematically eliminate contradictions to arrive at a valid solution.\nNotably, both GPT-4o and GPT-4o1 reached the same answer through slightly different reasoning:\nGPT-4o used a step-by-step contradiction approach, testing each individual‚Äôs truthfulness and discarding inconsistencies. GPT-4o1 opted for a more streamlined deduction, assuming Dana‚Äôs truthfulness and resolving the logical consequences. This exercise highlights LLMs‚Äô ability to process deductive logic, truth-value constraints, and contradictions, making them effective at solving structured reasoning puzzles.\nWould another LLM produce the same answer? Would performance change if the statements were reworded? Testing across different models could reveal nuances in AI logical reasoning and bias towards specific deduction styles.\nWhat do you think‚Äîshould we test other AI models on this problem?"
  },
  {
    "objectID": "posts/000_test_post/index.html",
    "href": "posts/000_test_post/index.html",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purple‚Ä¶\nBut it is possible you first said green (don‚Äôt worry if you did it is quite a common response!)\n\n\nIt‚Äôs a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | ‚Äî | ‚Äî | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt get‚Äôs it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. üü™\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, I‚Äôll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "posts/000_test_post/index.html#a-visualization-problem-for-llms",
    "href": "posts/000_test_post/index.html#a-visualization-problem-for-llms",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purple‚Ä¶\nBut it is possible you first said green (don‚Äôt worry if you did it is quite a common response!)\n\n\nIt‚Äôs a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | ‚Äî | ‚Äî | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt get‚Äôs it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. üü™\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, I‚Äôll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/missing number.html",
    "href": "posts/missing number.html",
    "title": "Third post about a math problem",
    "section": "",
    "text": "A teacher writes five numbers on the board:\n3, 5, 9, 17, ?\nShe tells her students that the pattern follows a logical rule.\nWhat number should replace the question mark (?) in the sequence?\nCan you figure it out?\n\n\nTo determine the missing number, let‚Äôs analyze the pattern in the sequence:\n3, 5, 9, 17, ?\nWe examine the differences between consecutive terms:\n5 ‚àí 3 = 2\n9 - 5 = 4\n17 ‚àí 9 = 8\nThis gives us the difference sequence:\n2, 4, 8\nObserving this pattern, we see that each difference doubles the previous one:\n2 , 4 , 8 , 16\nFollowing this doubling pattern, the next difference should be 16.\nThus, the missing number in the sequence is:\n17+16=33 ### Answer: 33"
  },
  {
    "objectID": "posts/missing number.html#solving-the-pattern",
    "href": "posts/missing number.html#solving-the-pattern",
    "title": "Third post about a math problem",
    "section": "",
    "text": "To determine the missing number, let‚Äôs analyze the pattern in the sequence:\n3, 5, 9, 17, ?\nWe examine the differences between consecutive terms:\n5 ‚àí 3 = 2\n9 - 5 = 4\n17 ‚àí 9 = 8\nThis gives us the difference sequence:\n2, 4, 8\nObserving this pattern, we see that each difference doubles the previous one:\n2 , 4 , 8 , 16\nFollowing this doubling pattern, the next difference should be 16.\nThus, the missing number in the sequence is:\n17+16=33 ### Answer: 33"
  },
  {
    "objectID": "posts/missing number.html#gpt-4os-approach",
    "href": "posts/missing number.html#gpt-4os-approach",
    "title": "Third post about a math problem",
    "section": "GPT-4o‚Äôs Approach",
    "text": "GPT-4o‚Äôs Approach\nGPT-4o follows a structured method to detect numerical patterns. It:\nIdentifies the differences between terms. Recognizes a doubling pattern in these differences. Extends the pattern logically to predict the next term. Computes the missing number using the established rule. üìå GPT-4o‚Äôs Answer: 33."
  },
  {
    "objectID": "posts/missing number.html#gpt-4o1s-approach",
    "href": "posts/missing number.html#gpt-4o1s-approach",
    "title": "Third post about a math problem",
    "section": "GPT-4o1‚Äôs Approach",
    "text": "GPT-4o1‚Äôs Approach\nGPT-4o1 arrives at the same conclusion using a similar approach:\nIt calculates the first-order differences: 2, 4, 8. It recognizes that each difference is doubling. It predicts the next difference as 16. It adds 16 to the last number (17) to find 33. üìå GPT-4o1‚Äôs Answer: 33."
  },
  {
    "objectID": "posts/Dice game.html",
    "href": "posts/Dice game.html",
    "title": "Game theory problem",
    "section": "",
    "text": "Imagine a simple gambling game where you roll a six-sided die and win the dollar amount that appears on the die. However, you have a strategic advantage: after rolling, you can either keep the result or choose to reroll. If you reroll, you must take the second roll‚Äôs value. How much would you pay to play such a game? And what if you had the option to roll a third time?\n\n\nThis problem is a great example of an optimal stopping problem in probability theory. The goal is to maximize the expected payout by deciding when to stop rolling.\n\n\nIf you could roll only once, the expected value (EV) of the game is simply the average outcome of rolling a fair six-sided die: [ EV = = 3.5 ] A rational investor would thus pay at most $3.50 to play the game if no rerolls were allowed.\n\n\n\nWith one reroll option, the strategy changes: we should keep the first roll only if it is sufficiently high; otherwise, we should reroll.\nIf the first roll is less than the expected value of rolling once (3.5), rerolling is the better option. Since dice rolls are discrete, we reroll when the first roll is 1, 2, or 3 and keep it otherwise.\nBy calculating the expected value when following this strategy, we find: [ EV_{2¬†rolls} = 4.25 ] So, a rational investor should pay up to $4.25 to play with one reroll option.\n\n\n\nNow, let‚Äôs extend the game to include a second reroll option. This means that after the first roll, you can either keep it, reroll, or reroll again if you still aren‚Äôt satisfied.\nUsing backward induction, we determine the optimal strategy: - If you reach the third roll, you must accept whatever you get, which has an expected value of 3.5. - If you reroll the second time, you should keep the result if it is 4, 5, or 6, otherwise, roll a third time. - On the first roll, it‚Äôs optimal to reroll unless you roll a 5 or 6.\nWith this strategy, the expected value of playing optimally with two rerolls is: [ EV_{3¬†rolls} = 4.83 ] Thus, the fair price for playing this game with two rerolls is $4.83.\n\n\n\n\n\nIf you roll once, the fair price is $3.50.\nWith one reroll, the fair price increases to $4.25.\nWith two rerolls, the fair price further increases to $4.83.\nThe more reroll opportunities you have, the higher the expected value‚Äîbut the increase diminishes with each additional reroll.\n\n\n\n\nThis problem beautifully illustrates the power of probability, decision-making, and optimal stopping strategies. If you ever encounter a similar game, now you know exactly how much you should be willing to pay!\nWould you take the bet? Let us know your thoughts!"
  },
  {
    "objectID": "posts/Dice game.html#the-optimal-dice-game-how-much-should-you-pay-to-play",
    "href": "posts/Dice game.html#the-optimal-dice-game-how-much-should-you-pay-to-play",
    "title": "Game theory problem",
    "section": "",
    "text": "Imagine a simple gambling game where you roll a six-sided die and win the dollar amount that appears on the die. However, you have a strategic advantage: after rolling, you can either keep the result or choose to reroll. If you reroll, you must take the second roll‚Äôs value. How much would you pay to play such a game? And what if you had the option to roll a third time?\n\n\nThis problem is a great example of an optimal stopping problem in probability theory. The goal is to maximize the expected payout by deciding when to stop rolling.\n\n\nIf you could roll only once, the expected value (EV) of the game is simply the average outcome of rolling a fair six-sided die: [ EV = = 3.5 ] A rational investor would thus pay at most $3.50 to play the game if no rerolls were allowed.\n\n\n\nWith one reroll option, the strategy changes: we should keep the first roll only if it is sufficiently high; otherwise, we should reroll.\nIf the first roll is less than the expected value of rolling once (3.5), rerolling is the better option. Since dice rolls are discrete, we reroll when the first roll is 1, 2, or 3 and keep it otherwise.\nBy calculating the expected value when following this strategy, we find: [ EV_{2¬†rolls} = 4.25 ] So, a rational investor should pay up to $4.25 to play with one reroll option.\n\n\n\nNow, let‚Äôs extend the game to include a second reroll option. This means that after the first roll, you can either keep it, reroll, or reroll again if you still aren‚Äôt satisfied.\nUsing backward induction, we determine the optimal strategy: - If you reach the third roll, you must accept whatever you get, which has an expected value of 3.5. - If you reroll the second time, you should keep the result if it is 4, 5, or 6, otherwise, roll a third time. - On the first roll, it‚Äôs optimal to reroll unless you roll a 5 or 6.\nWith this strategy, the expected value of playing optimally with two rerolls is: [ EV_{3¬†rolls} = 4.83 ] Thus, the fair price for playing this game with two rerolls is $4.83.\n\n\n\n\n\nIf you roll once, the fair price is $3.50.\nWith one reroll, the fair price increases to $4.25.\nWith two rerolls, the fair price further increases to $4.83.\nThe more reroll opportunities you have, the higher the expected value‚Äîbut the increase diminishes with each additional reroll.\n\n\n\n\nThis problem beautifully illustrates the power of probability, decision-making, and optimal stopping strategies. If you ever encounter a similar game, now you know exactly how much you should be willing to pay!\nWould you take the bet? Let us know your thoughts!"
  }
]